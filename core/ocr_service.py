# ocr_qwen2vl_mlx.py
from mlx_vlm import load, generate
from PIL import Image
import requests
from io import BytesIO
import os


class QwenOcrService:
    # def __init__(self):
    #     print("ğŸ”„ Loading Qwen2-VL-2B-Instruct-4bit (MLX)...")
    #     self.model_path = "mlx-community/Qwen2-VL-2B-Instruct-4bit"
    #     try:
    #         # åŠ è½½ MLX æ ¼å¼çš„æ¨¡å‹å’Œå¤„ç†å™¨
    #         self.model, self.processor = load(
    #             self.model_path,
    #             trust_remote_code=True
    #         )
    #         print("âœ… Model loaded successfully on Apple Silicon.")
    #     except Exception as e:
    #         print(f"âŒ Failed to load model: {e}")
    #         raise

    def _load_image(self, image_url: str) -> Image.Image:
        """ç»Ÿä¸€åŠ è½½å›¾åƒï¼šæ”¯æŒæœ¬åœ°è·¯å¾„å’Œ HTTP/HTTPS URL"""
        if image_url.startswith(("http://", "https://")):
            response = requests.get(image_url, timeout=10)
            response.raise_for_status()
            image = Image.open(BytesIO(response.content)).convert("RGB")
        else:
            if not os.path.exists(image_url):
                raise FileNotFoundError(f"Local image not found: {image_url}")
            image = Image.open(image_url).convert("RGB")
        return image

    def extract_text(self, image_url: str,
                     prompt: str = "Extract all visible text from the image exactly as it appears.") -> str:
        """
        ä½¿ç”¨ Qwen2-VL æ‰§è¡Œ OCRã€‚
        :param image_url: å›¾åƒçš„æœ¬åœ°è·¯å¾„æˆ– HTTP(S) URL
        :param prompt: æç¤ºè¯ï¼ˆå»ºè®®æ˜ç¡®è¦æ±‚æå–æ–‡å­—ï¼‰
        :return: æ¨¡å‹ç”Ÿæˆçš„æ–‡æœ¬
        """
        try:
            # 1. åŠ è½½å›¾åƒä¸º PIL Imageï¼ˆå¿…é¡»ï¼ï¼‰
            image = self._load_image(image_url)

            # 2. è°ƒç”¨ generate â€”â€” æ³¨æ„ï¼šä¸è¦æ‰‹åŠ¨ apply_chat_templateï¼
            # mlx_vlm å†…éƒ¨ä¼šè‡ªåŠ¨æ„å»ºå¤šæ¨¡æ€è¾“å…¥
            output = generate(
                model=self.model,
                processor=self.processor,
                image=image,  # â† å¿…é¡»æ˜¯ PIL Image
                prompt=prompt,  # â† çº¯æ–‡æœ¬æç¤º
                max_tokens=1024,
                temperature=0.0,  # ä½æ¸©æé«˜ç¡®å®šæ€§
                repetition_penalty=1.1,
                verbose=False
            )

            return output.strip()

        except Exception as e:
            print(f"âŒ OCR inference error: {e}")
            import traceback
            traceback.print_exc()
            return ""


# === ä½¿ç”¨ç¤ºä¾‹ ===
if __name__ == "__main__":
    ocr = QwenOcrService()

    # ç¤ºä¾‹1ï¼šæœ¬åœ°å›¾ç‰‡
    text1 = ocr.extract_text("https://images.pexels.com/photos/34738471/pexels-photo-34738471.jpeg", "What text is written in this image?")
    print("OCR Result (local):", text1)
