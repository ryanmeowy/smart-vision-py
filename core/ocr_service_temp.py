from paddleocr import PaddleOCR
import numpy as np


class OCRService:
    def __init__(self):
        print("ğŸ”„ Loading PaddleOCR...")
        self.ocr = PaddleOCR(use_angle_cls=True, lang='ch')
        print("âœ… PaddleOCR loaded.")

    def extract_text(self, image):
        img_array = np.array(image)
        result = self.ocr.ocr(img_array, cls=True)

        full_text = ""
        lines = []
        if result and result[0]:
            for line in result[0]:
                text = line[1][0]
                lines.append(text)
                full_text += text + " "

        return full_text.strip(), lines

# ocr_service = OCRService()


from mlx_vlm import load, generate
from mlx_vlm.prompt_utils import apply_chat_template
from mlx_vlm.utils import load_config


if __name__ == "__main__":
    # Load the model
    model, processor = load("mlx-community/Qwen2-VL-2B-Instruct-4bit")
    config = load_config("mlx-community/Qwen2-VL-2B-Instruct-4bit")

    # Prepare input
    image = ["https://images.pexels.com/photos/34738471/pexels-photo-34738471.jpeg"]
    prompt = "è¯·ç²¾ç¡®æå–å›¾ä¸­çš„æ‰€æœ‰æ–‡æœ¬å†…å®¹ï¼ŒåŒ…æ‹¬å°åˆ·ä½“å’Œæ¸…æ™°çš„æ‰‹å†™ä½“ã€‚è¯·å¿½ç•¥æ°´å°ï¼Œå¹¶ä¸¢å¼ƒæ— æ„ä¹‰çš„æ–‡æœ¬ï¼ˆå¦‚å•ä¸ªæ ‡ç‚¹ç¬¦å·ã€æ— ä¸Šä¸‹æ–‡çš„å­¤ç«‹å­—ç¬¦ï¼‰ã€‚è‹¥å›¾ä¸­æ²¡æœ‰æ–‡æœ¬ã€æ–‡æœ¬æ— æ³•è¯†åˆ«æˆ–éš¾ä»¥è¯†åˆ«ï¼Œè¯·è¾“å‡ºâ€œ-1â€ã€‚è‹¥æœ‰æ–‡æœ¬ï¼Œè¯·ç›´æ¥è¾“å‡ºæå–åˆ°çš„æ–‡æœ¬ï¼Œä¸è¦è¾“å‡ºä»»ä½•ä¸å›¾ä¸­æ–‡æœ¬æ— å…³çš„å†…å®¹ã€‚"

    # Apply chat template
    formatted_prompt = apply_chat_template(
        processor, config, prompt, num_images=1
    )

    # Generate output
    output = generate(model, processor, formatted_prompt, image)
    print(output)