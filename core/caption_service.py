import json
import os
import re

from mlx_vlm import load, generate

from utils.image_loader import get_image_smart

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"


def _clean_json_output(text: str):
    text = re.sub(r"```json\s*", "", text)
    text = re.sub(r"```\s*$", "", text)
    text = text.strip()
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        return []


def _clean_and_validate_title(text: str) -> str:
    if not text:
        return "æœªå‘½åå›¾ç‰‡"

    # --- ç§»é™¤å¸¸è§çš„å‰ç¼€å¹²æ‰°è¯ ---
    remove_words = ["æ ‡é¢˜", "å›¾ç‰‡", "å†…å®¹", "åç§°"]
    for word in remove_words:
        text = text.replace(word, "")

    # --- æ­£åˆ™æå–çº¯ä¸­æ–‡ ---
    chinese_chars = re.findall(r'[\u4e00-\u9fa5]', text)

    clean_text = "".join(chinese_chars)

    # --- é•¿åº¦ä¸ç©ºå€¼å…œåº• ---
    if not clean_text:
        return "æœªå‘½åå›¾ç‰‡"

    # è¶…è¿‡6ä¸ªå­—æˆªå–
    if len(clean_text) > 6:
        clean_text = clean_text[:6]

    if len(clean_text) < 2:
        return "æœªå‘½åå›¾ç‰‡"

    return clean_text


def _clean_tags_output(raw_text: str) -> list[str]:
    if not raw_text:
        return []

    try:
        match = re.search(r'\[.*?]', raw_text, re.DOTALL)
        if match:
            json_str = match.group()
            try:
                tags_list = json.loads(json_str)
            except json.JSONDecodeError:
                tags_list = re.findall(r'["\'](.*?)["\']', json_str)
        else:
            clean_text = raw_text.replace("```json", "").replace("```", "").strip()
            tags_list = re.split(r'[ï¼Œ,ã€\n]+', clean_text)

        # --- å¤„ç†å¤è¯»æœº ---
        seen = set()
        clean_tags = []

        for tag in tags_list:
            if not isinstance(tag, str):
                tag = str(tag)
            tag = tag.strip()

            if not tag or len(tag) > 8:
                continue

            if tag not in seen:
                clean_tags.append(tag)
                seen.add(tag)

        if not clean_tags:
            return ["æœªåˆ†ç±»"]

        return clean_tags[:5]

    except Exception as e:
        print(f"âŒ Tags parsing error: {e}, raw: {raw_text}")
        return ["æœªåˆ†ç±»"]


def _clean_graph_triples(text: str):
    try:
        text = re.sub(r"```json\s*", "", text)
        text = re.sub(r"```\s*$", "", text)
        text = text.strip()
        matches = re.findall(r'\{[^{}]+}', text)
        triples = []
        seen = set()
        for match in matches:
            try:
                obj = json.loads(match)
                if not all(k in obj for k in ('s', 'p', 'o')):
                    continue
                fingerprint = f"{obj['s']}|{obj['p']}|{obj['o']}"
                if fingerprint not in seen:
                    seen.add(fingerprint)
                    triples.append(obj)
            except:
                continue
        print(f"âœ… Graph extracted: {len(triples)} triples")
        return triples
    except Exception as e:
        print(f"âŒ Parsing Error: {e}")
        return []


class CaptionService:
    def __init__(self):
        self.model_path = "mlx-community/Qwen2.5-VL-7B-Instruct-4bit"
        print(f"ğŸ”„ Loading: {self.model_path} ...")
        self.model, self.processor = load(self.model_path)
        print(f"âœ… {self.model_path} loaded")

    def generate_name(self, image_url: str):
        image = get_image_smart(image_url)
        prompt = """
        ä¸ºè¿™å¼ å›¾ç‰‡èµ·ä¸€ä¸ª3-6å­—çš„ä¸­æ–‡æ ‡é¢˜ï¼Œè¦æ±‚ç¾æ„Ÿã€ç®€æ´ã€è¯—æ„ã€‚
        ä¸èƒ½æœ‰é™¤ä¸­æ–‡å¤–çš„å…¶ä»–å­—ç¬¦æˆ–è€…æ ‡ç‚¹ç¬¦å·ã€‚æ ‡é¢˜ä¸èƒ½è¶…è¿‡6ä¸ªå­—ã€‚
        ç›´æ¥è¾“å‡ºæ ‡é¢˜ï¼Œä¸è¦åŒ…å«å…¶ä»–å­—ç¬¦ã€‚
        ç¤ºä¾‹1ï¼š
        å›¾ç‰‡å†…å®¹ï¼šä¸€åªæ©˜çŒ«åœ¨ç¡è§‰
        æ ‡é¢˜ï¼šæ©˜çŒ«åˆç¡
        ç¤ºä¾‹2ï¼š
        å›¾ç‰‡å†…å®¹ï¼šç¹åçš„åŸå¸‚å¤œæ™¯
        æ ‡é¢˜ï¼šåŸå¸‚éœ“è™¹
        """
        formatted_prompt = self.processor.apply_chat_template(
            [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": prompt}]}],
            add_generation_prompt=True,
        )
        output = generate(
            self.model,
            self.processor,
            image=image,
            prompt=formatted_prompt,
            verbose=False,
            max_tokens=10,
            temp=0.5
        )
        return _clean_and_validate_title(output)

    def generate_tags(self, image_url: str):
        image = get_image_smart(image_url)
        prompt = """
        åˆ†æå›¾ç‰‡ï¼Œæå–3-5ä¸ªæ ¸å¿ƒä¸­æ–‡æ ‡ç­¾(ç‰©ä½“ã€åœºæ™¯ã€é£æ ¼)ã€‚
        ä¸¥æ ¼è¿”å›JSONå­—ç¬¦ä¸²æ•°ç»„ï¼Œä¾‹å¦‚ï¼š["é£æ™¯", "é›ªå±±", "æ—¥è½"]ã€‚
        ä¸è¦è¾“å‡ºMarkdownæ ¼å¼ï¼Œä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚æ ‡ç­¾æ•°é‡ä¸è¦å°‘äº3ä¸ª
        """

        formatted_prompt = self.processor.apply_chat_template(
            [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": prompt}]}],
            add_generation_prompt=True,
        )

        output = generate(
            self.model,
            self.processor,
            image=image,
            prompt=formatted_prompt,
            verbose=False,
            max_tokens=200,
            temp=0.7
        )
        return _clean_tags_output(output)

    def extract_graph_triples(self, image_url: str):
        image = get_image_smart(image_url)
        prompt = """
                è¯·åˆ†æå›¾ç‰‡ï¼Œæå–å›¾ä¸­ä¸»è¦ç‰©ä½“ä¹‹é—´çš„ SPO ä¸‰å…ƒç»„ã€‚
                è¯·ä»¥ JSON æ•°ç»„æ ¼å¼è¿”å›ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ä¸‰ä¸ªå­—æ®µï¼š
                - "s": Subject (ä¸»ä½“ï¼Œåè¯)
                - "p": Predicate (å…³ç³»ï¼Œå¦‚ï¼šä½äºã€æ‹¿ç€ã€ç©¿ç€ã€åŒ…å«ï¼ŒåŠ¨è¯/ä»‹è¯)
                - "o": Object (å®¢ä½“ï¼Œåè¯)
                
                ã€ç¤ºä¾‹ã€‘ï¼š
                è¾“å…¥ï¼šä¸€å¼ ç”·äººç«™åœ¨å±±é¡¶çœ‹æ—¥å‡ºçš„å›¾ã€‚
                è¾“å‡ºï¼š
                [
                  {"s": "ç”·å­", "p": "ç«™åœ¨", "o": "å±±é¡¶"},
                  {"s": "ç”·å­", "p": "é¢å‘", "o": "å¤ªé˜³"},
                  {"s": "äº‘æµ·", "p": "ç¯ç»•", "o": "å±±è…°"}
                ]
                
                è¯·è¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦Markdownä»£ç å—ï¼Œå¿…é¡»æ˜¯ä¸­æ–‡ã€‚
        """

        formatted_prompt = self.processor.apply_chat_template(
            [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": prompt}]}],
            add_generation_prompt=True,
        )
        output = generate(
            self.model,
            self.processor,
            image=image,
            prompt=formatted_prompt,
            verbose=False,
            max_tokens=256,
            temp=0.3,
            repetition_penalty=1.0,
            do_sample=True,
            top_p=0.9
        )

        return _clean_graph_triples(output)

    def stream_generate(self, image_url: str, prompt: str):
        image = get_image_smart(image_url)

        formatted_prompt = self.processor.apply_chat_template(
            [{"role": "user", "content": [{"type": "image"}, {"type": "text", "text": prompt}]}],
            add_generation_prompt=True,
        )

        # ä½¿ç”¨æµå¼ç”Ÿæˆæ¨¡å¼
        stream_output = generate(
            self.model,
            self.processor,
            image=image,
            prompt=formatted_prompt,
            verbose=False,
            max_tokens=500,
            temp=0.7,
            stream=True  # å¯ç”¨æµå¼è¾“å‡º
        )

        # é€ä¸ªyieldç”Ÿæˆçš„token
        for chunk in stream_output:
            yield chunk

    def parse_query_to_graph(self, query: str):
        system_prompt = """
                ä½ æ˜¯ä¸€ä¸ªæœç´¢æ„å›¾è§£æå™¨ã€‚è¯·æå–ç”¨æˆ·æŸ¥è¯¢ä¸­çš„ã€å®ä½“å…³ç³»ã€‘ï¼Œå¹¶æ ‡å‡†ä¸º JSON ä¸‰å…ƒç»„ã€‚
                - "s": Subject (ä¸»ä½“ï¼Œåè¯)
                - "p": Predicate (å…³ç³»ï¼Œå¦‚ï¼šä½äºã€æ‹¿ç€ã€ç©¿ç€ã€åŒ…å«ï¼ŒåŠ¨è¯/ä»‹è¯)
                - "o": Object (å®¢ä½“ï¼Œåè¯)

                ã€ç¤ºä¾‹ã€‘ï¼š
                è¾“å…¥ï¼š"æ‰¾ä¸€åªåœ¨ç¡è§‰çš„æ©˜çŒ«" -> è¾“å‡ºï¼š[{"s":"æ©˜çŒ«", "p":"çŠ¶æ€", "o":"ç¡è§‰"}, {"s":"æ©˜çŒ«", "p":"é¢œè‰²", "o":"æ©˜è‰²"}]
                è¾“å…¥ï¼š"çº¢è‰²çš„æ³•æ‹‰åˆ©" -> è¾“å‡ºï¼š[{"s":"æ³•æ‹‰åˆ©", "p":"é¢œè‰²", "o":"çº¢è‰²"}]
                è¾“å…¥: "çˆ¬é›ªå±±çš„ç”·äºº" -> è¾“å‡º: [{"s":"ç”·äºº", "p":"çˆ¬", "o":"é›ªå±±"}, {"s":"ç”·äºº", "p":"åŠ¨ä½œ", "o":"çˆ¬"}]
                
                è¯·è¾“å‡º JSON æ•°ç»„ï¼Œä¸è¦Markdownä»£ç å—ï¼Œå¿…é¡»æ˜¯ä¸­æ–‡ã€‚
                """
        full_text_prompt = f"{system_prompt}\nè¾“å…¥ï¼š{query}\nè¾“å‡ºï¼š"
        messages = [
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": full_text_prompt},
                ],
            }
        ]

        text = self.processor.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )

        output = generate(
            self.model,
            self.processor,
            prompt=text,
            max_tokens=256,
            temperature=0.1,
            verbose=False
        )
        return _clean_json_output(output)


caption_service = CaptionService()

if __name__ == "__main__":
    service = CaptionService()
    # url = "https://images.pexels.com/photos/5026339/pexels-photo-5026339.jpeg"

    # print("Name:", service.generate_name(url))
    # print("Tags:", service.generate_tags(url))
    # print("Graph Triples:", service.extract_graph_triples(url))
    print(service.parse_query_to_graph("å¥”è·‘çš„ç”·äºº"))
